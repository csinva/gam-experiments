{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import ElasticNetCV, LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "from sklearn.utils.validation import check_X_y\n",
    "from sklearn.utils.validation import _check_sample_weight\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor, AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import dvu\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from matplotlib.colors import Normalize\n",
    "import joblib\n",
    "import viz\n",
    "from interpret import show\n",
    "\n",
    "import imodels\n",
    "from interpret.glassbox import ExplainableBoostingClassifier, ExplainableBoostingRegressor\n",
    "\n",
    "from sklearn.base import RegressorMixin, ClassifierMixin\n",
    "from imodels.algebraic.gam_multitask import MultiTaskGAMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit some simple GAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching 42712 from openml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [04:57<00:00, 24.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_corr 0.794\n",
      "test r2 0.63\n",
      "fetching 42712 from openml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [04:54<00:00, 24.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_corr 0.836\n",
      "test r2 0.699\n",
      "fetching california_housing from sklearn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:41<00:00, 12.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_corr 0.858\n",
      "test r2 0.736\n",
      "fetching california_housing from sklearn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:25<00:00, 10.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_corr 0.876\n",
      "test r2 0.767\n",
      "fetching diabetes from sklearn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:35<00:00,  3.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_corr 0.701\n",
      "test r2 0.491\n",
      "fetching diabetes from sklearn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:36<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_corr 0.641\n",
      "test r2 0.351\n",
      "fetching heart from imodels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:31<00:00,  6.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_corr 0.731\n",
      "test r2 0.518\n",
      "fetching heart from imodels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:33<00:00,  6.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_corr 0.692\n",
      "test r2 0.472\n"
     ]
    }
   ],
   "source": [
    "dset = 'bike_sharing'\n",
    "# dset = 'california_housing'\n",
    "# dset = 'diabetes_regr'\n",
    "# dset = 'heart'\n",
    "fit_target_curves = False\n",
    "for dset in ['bike_sharing', 'california_housing', 'diabetes_regr', 'heart']:\n",
    "    for fit_target_curves in [False, True]:\n",
    "        X, y, feature_names = imodels.get_clean_dataset(dset)\n",
    "        X, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "        kwargs = dict(\n",
    "            random_state=42,\n",
    "            n_jobs=-2,\n",
    "        )\n",
    "        results = defaultdict(list)\n",
    "\n",
    "        gam = MultiTaskGAMRegressor(\n",
    "            multitask=True, interactions=False, fit_target_curves=fit_target_curves)\n",
    "\n",
    "        np.random.seed(42)\n",
    "        gam.fit(X, y_train)\n",
    "        print('test_corr', np.corrcoef(\n",
    "            y_test, gam.predict(X_test))[0, 1].round(3))\n",
    "        print('test r2', gam.score(X_test, y_test).round(3))\n",
    "        joblib.dump(\n",
    "            gam, f'../figs/{dset}_gam_fit_target_curves={fit_target_curves}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the GAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gam = joblib.load(\n",
    "    f'../figs/{dset}_gam_fit_target_curves={fit_target_curves}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_target_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate linspace curves for each feature and show EBM evals of all of them\n",
    "mins = X.min(axis=0)\n",
    "maxes = X.max(axis=0)\n",
    "n = 100\n",
    "linspaces = [np.linspace(mins[i], maxes[i], n) for i in range(X.shape[1])]\n",
    "linspaces = np.array(linspaces).T\n",
    "evals = gam._extract_ebm_features(linspaces)\n",
    "num_ebms = len(gam.ebms_)\n",
    "num_features = X.shape[1]\n",
    "\n",
    "C = 3\n",
    "R = int(np.ceil(num_features / C))\n",
    "plt.figure(figsize=(C * 4,  R * 3))\n",
    "# grid = plt.GridSpec(R, C, hspace=0.4)\n",
    "for feat_num in range(num_features):\n",
    "    # r = feat_num // C\n",
    "    # c = feat_num % C\n",
    "    # plt.subplot(grid[r, c])\n",
    "    plt.subplot(R, C, feat_num + 1)\n",
    "    for ebm_num in range(num_ebms):\n",
    "\n",
    "        idxs_feat_num = np.arange(\n",
    "            feat_num, num_ebms * num_features, num_features)\n",
    "        coefs = gam.lin_model.coef_[idxs_feat_num]\n",
    "\n",
    "        # get diverging colormap based on coefs\n",
    "        colors = viz._get_diverging_colors_centered_at_zero(coefs[:-1])\n",
    "\n",
    "        if fit_target_curves:\n",
    "            idxs = idxs_feat_num[:-1]\n",
    "        else:\n",
    "            idxs = idxs_feat_num\n",
    "        for feat_name_predicting, idx in enumerate(idxs):\n",
    "            plt.plot(linspaces[:, feat_num],\n",
    "                     evals[:, idx],\n",
    "                     alpha=0.5,\n",
    "                     label=str(feature_names[feat_name_predicting]),\n",
    "                     color=colors[feat_name_predicting])\n",
    "        if fit_target_curves:\n",
    "            plt.plot(linspaces[:, feat_num],\n",
    "                     evals[:, idxs_feat_num[-1]], color='#444', linestyle=':', label='initial', lw=4)\n",
    "\n",
    "    plt.plot(linspaces[:, feat_num], np.dot(\n",
    "        evals[:, idxs_feat_num], coefs), color='black', lw=3, label='multi-task')\n",
    "    plt.xlabel(feature_names[feat_num])\n",
    "\n",
    "    dvu.line_legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f'../figs/gam_curves/{dset}_fit_target_curves={fit_target_curves}.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".embgam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
