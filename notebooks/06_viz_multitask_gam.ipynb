{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import ElasticNetCV, LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "from sklearn.utils.validation import check_X_y\n",
    "from sklearn.utils.validation import _check_sample_weight\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor, AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import dvu\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from matplotlib.colors import Normalize\n",
    "import joblib\n",
    "import viz\n",
    "from interpret import show\n",
    "\n",
    "import imodels\n",
    "from interpret.glassbox import ExplainableBoostingClassifier, ExplainableBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import RegressorMixin, ClassifierMixin\n",
    "from imodels.algebraic.gam_multitask import MultiTaskGAMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit some simple GAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = 'bike_sharing'\n",
    "# dset = 'california_housing'\n",
    "# dset = 'diabetes_regr'\n",
    "# dset = 'heart'\n",
    "fit_target_curves = False\n",
    "for dset in ['bike_sharing', 'california_housing', 'diabetes_regr', 'heart']:\n",
    "    for fit_target_curves in [True]:\n",
    "        X, y, feature_names = imodels.get_clean_dataset(dset)\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "        y = StandardScaler().fit_transform(y.reshape(-1, 1)).ravel()\n",
    "        X, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "        kwargs = dict(\n",
    "            random_state=42,\n",
    "            n_jobs=-2,\n",
    "        )\n",
    "        results = defaultdict(list)\n",
    "\n",
    "        gam = MultiTaskGAMRegressor(\n",
    "            multitask=True, interactions=False, fit_target_curves=fit_target_curves)\n",
    "\n",
    "        np.random.seed(42)\n",
    "        gam.fit(X, y_train)\n",
    "        print('test_corr', np.corrcoef(\n",
    "            y_test, gam.predict(X_test))[0, 1].round(3))\n",
    "        print('test r2', gam.score(X_test, y_test).round(3))\n",
    "        joblib.dump(\n",
    "            gam, f'../figs/{dset}_gam_fit_target_curves={fit_target_curves}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the GAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dset(dset, fit_target_curves=True):\n",
    "    gam = joblib.load(\n",
    "        f'../figs/{dset}_gam_fit_target_curves={fit_target_curves}.pkl')\n",
    "    X, y, feature_names = imodels.get_clean_dataset(dset)\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    y = StandardScaler().fit_transform(y.reshape(-1, 1)).ravel()\n",
    "    X, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "    # generate linspace curves for each feature and show EBM evals of all of them\n",
    "    mins = X.min(axis=0)\n",
    "    maxes = X.max(axis=0)\n",
    "    n = 100\n",
    "    linspaces = [np.linspace(mins[i], maxes[i], n) for i in range(X.shape[1])]\n",
    "    linspaces = np.array(linspaces).T\n",
    "    evals = gam._extract_ebm_features(linspaces)\n",
    "    num_ebms = len(gam.ebms_)\n",
    "    num_features = X.shape[1]\n",
    "\n",
    "    C = 3\n",
    "    R = int(np.ceil(num_features / C))\n",
    "    plt.figure(figsize=((C + 1) * 5.5,  R * 3))\n",
    "    grid = plt.GridSpec(R, C + 1)  # , hspace=1.0, vspace=0.1)\n",
    "    for feat_num in tqdm(range(num_features)):\n",
    "        r = feat_num // C\n",
    "        c = feat_num % C\n",
    "        plt.subplot(grid[r, c])\n",
    "        # plt.subplot(R, C, feat_num + 1)\n",
    "        for ebm_num in range(num_ebms):\n",
    "\n",
    "            idxs_feat_num = np.arange(\n",
    "                feat_num, num_ebms * num_features, num_features)\n",
    "            coefs = gam.lin_model.coef_[idxs_feat_num]\n",
    "\n",
    "            # get diverging colormap based on coefs\n",
    "            colors = viz._get_diverging_colors_centered_at_zero(coefs[:-1])\n",
    "\n",
    "            if fit_target_curves:\n",
    "                idxs = idxs_feat_num[:-1]\n",
    "            else:\n",
    "                idxs = idxs_feat_num\n",
    "            for feat_name_predicting, idx in enumerate(idxs):\n",
    "                plt.plot(linspaces[:, feat_num],\n",
    "                         evals[:, idx],\n",
    "                         alpha=0.5,\n",
    "                         label=str(feature_names[feat_name_predicting]),\n",
    "                         color=colors[feat_name_predicting])\n",
    "            if fit_target_curves:\n",
    "                plt.plot(linspaces[:, feat_num],\n",
    "                         evals[:, idxs_feat_num[-1]], color='#444', linestyle=':', label='initial', lw=4)\n",
    "\n",
    "        plt.plot(linspaces[:, feat_num], np.dot(\n",
    "            evals[:, idxs_feat_num], coefs), color='black', lw=3, label='multi-task')\n",
    "        plt.xlabel(feature_names[feat_num])\n",
    "\n",
    "        dvu.line_legend()\n",
    "\n",
    "    # add plot to the top right\n",
    "    if fit_target_curves:\n",
    "        plt.subplot(grid[0:2, -1])\n",
    "        coefs_final = gam.lin_model.coef_[-num_features:]\n",
    "        coefs_feat = gam.lin_model.coef_[:-num_features]\n",
    "        plt.hist(coefs_final, bins=20, density=True,\n",
    "                 color='black', label='Target curve coefs')\n",
    "        plt.hist(coefs_feat, bins=20, density=True,\n",
    "                 label='Feature curve coefs', alpha=0.5)\n",
    "        plt.xlabel('Coefficient')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f'../figs/gam_curves/{dset}_fit_target_curves={fit_target_curves}.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for dset in ['bike_sharing', 'california_housing', 'diabetes_regr', 'heart']:\n",
    "    visualize_dset(dset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".embgam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
